{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.053320Z",
     "start_time": "2019-02-15T11:09:14.595120Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ssl\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import heapq\n",
    "import itertools\n",
    "import random\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.plotly as py\n",
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.067405Z",
     "start_time": "2019-02-15T11:09:18.058435Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_preprocessing():\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(\"intrusion_detection.csv\")\n",
    "    df[\"xAttack\"] = df.apply(convert_string_to_float, axis=1)\n",
    "\n",
    "    X = df.values[:, :-1] \n",
    "    y = df.values[:, -1]\n",
    "    \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.3,random_state = 0) \n",
    "\n",
    "    X_train = feature_scaling(X_train)\n",
    "    \n",
    "#     train_data = X_train\n",
    "#     train_data[:,-1] = y_train\n",
    "\n",
    "#     validation_data = X_validation\n",
    "#     validation_data[:,-1] = y_validation\n",
    "\n",
    "#     validation_df = pd.DataFrame(validation_data)\n",
    "    \n",
    "    return X_train, X_validation, y_train, y_validation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.080957Z",
     "start_time": "2019-02-15T11:09:18.068687Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split_data(df, size):\n",
    "    \n",
    "    if isinstance(size, float):\n",
    "        size = round(size * len(df))\n",
    "    \n",
    "    #getting indexes of dataset in a list\n",
    "    indices = df.index.tolist()\n",
    "    \n",
    "    #randomly choosing \"size\" number of indices for validation set\n",
    "    indices = random.sample(population=indices, k=size)\n",
    "\n",
    "    #Creating validation set\n",
    "    validation_df = df.loc[indices]\n",
    "    \n",
    "    #Creating trianing set\n",
    "    train_df = df.drop(indices)\n",
    "    \n",
    "    return train_df, validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.140864Z",
     "start_time": "2019-02-15T11:09:18.082242Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_scaling(train_data):\n",
    "    \n",
    "    no_of_columns = train_data.shape[1]\n",
    "    \n",
    "    global sd_mean_list\n",
    "    \n",
    "    sd_mean_list = []\n",
    "    \n",
    "    for index in range(no_of_columns):\n",
    "\n",
    "        sd_val = np.std(train_data[:,index])\n",
    "        mean_val = np.mean(train_data[:,index])\n",
    "        train_data[:,index] = (train_data[:,index] - mean_val)/(sd_val)\n",
    "        \n",
    "        sd_mean_list.append([sd_val,mean_val])\n",
    "        \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.151279Z",
     "start_time": "2019-02-15T11:09:18.143252Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_test_data(X_test):\n",
    "    \n",
    "    global sd_mean_list\n",
    "    \n",
    "    for test_row in X_test:\n",
    "        \n",
    "        for index in range(len(test_row)):\n",
    "\n",
    "            mean = sd_mean_list[index][1]\n",
    "            sd = sd_mean_list[index][0]\n",
    "\n",
    "            test_row[index] = (test_row[index] - mean)/sd\n",
    "\n",
    "    return X_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.162784Z",
     "start_time": "2019-02-15T11:09:18.153425Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_string_to_float(test_row):\n",
    "    \n",
    "    if test_row[-1] == \"normal\":\n",
    "        return 0\n",
    "    elif test_row[-1] == \"dos\":\n",
    "        return  1\n",
    "    elif test_row[-1] == \"u2r\":\n",
    "        return  2\n",
    "    elif test_row[-1] == \"r2l\":\n",
    "        return  3\n",
    "    elif test_row[-1] == \"probe\":\n",
    "        return  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.195162Z",
     "start_time": "2019-02-15T11:09:18.164337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def d22():\n",
    "    X_train, X_validation, y_train, y_validation = data_preprocessing()\n",
    "\n",
    "    # X_train = X_train - np.mean(X_train, axis=0)\n",
    "\n",
    "    # covmat = np.dot(X_train.T,X_train)/(X_train.shape[0])\n",
    "\n",
    "    # U, S, V = svd(covmat)\n",
    "\n",
    "    # print(covmat.shape)\n",
    "    # print(U.shape)\n",
    "    # print(S.shape)\n",
    "    # print(V.shape)\n",
    "\n",
    "    # k = 15\n",
    "\n",
    "    # Z = np.dot(X_train,U[:,0:k])\n",
    "\n",
    "    # print(Z)\n",
    "\n",
    "    # S_D = np.diag(S)\n",
    "\n",
    "    # X_regenerate = np.dot(U[:,0:k],np.dot(S_D[0:k,:],V.T))\n",
    "\n",
    "    # print(np.allclose(X_regenerate,covmat))\n",
    "\n",
    "    # print(X_regenerate.shape)\n",
    "    # print(X_regenerate[0])\n",
    "    # print(covmat[0])\n",
    "\n",
    "    # u, s, vh = np.linalg.svd(covmat, full_matrices=True)\n",
    "    # print(u.shape, s.shape, vh.shape)\n",
    "\n",
    "    # np.allclose(covmat, np.dot(u[:, :k] * s, vh))\n",
    "\n",
    "    # smat = np.zeros((29, k), dtype=complex)\n",
    "    # smat[:k, :k] = np.diag(s)\n",
    "    # np.allclose(a, np.dot(u, np.dot(smat, vh)))\n",
    "    from scipy.linalg import svd\n",
    "    k = 27\n",
    "    # u, s, vh = np.linalg.svd(X_train, full_matrices=False)\n",
    "    print(X_train.T.shape)\n",
    "    u, s, vh = svd(X_train.T, full_matrices=False)\n",
    "\n",
    "    print(u.shape, s.shape, vh.shape)\n",
    "    # print(X_train.shape)\n",
    "\n",
    "    X_train = X_train.T\n",
    "\n",
    "    Sigma = np.zeros((X_train.shape[0], X_train.shape[1]))\n",
    "    Sigma[:X_train.shape[0], :X_train.shape[0]] = np.diag(s)\n",
    "\n",
    "    Sigma = Sigma[:, :k]\n",
    "    vh = vh[:k, :]\n",
    "    # reconstruct\n",
    "    B = u.dot(np.dot(Sigma,vh))\n",
    "    print(B.shape)\n",
    "    # transform\n",
    "    print(u.shape, s.shape, vh.shape)\n",
    "    T = np.dot(u,Sigma)\n",
    "    # print(T)\n",
    "    print(T.shape)\n",
    "    T = np.dot(X_train,vh.T)\n",
    "    print(T.shape)\n",
    "\n",
    "    # print(np.allclose(X_train, np.matmul(u[:,0:k] * s[0:k], vh[0:k,:])))\n",
    "\n",
    "    # print(np.allclose(X_train, np.matmul(u, s[..., None] * vh)))\n",
    "\n",
    "    # k = 27\n",
    "\n",
    "    # Z = np.dot(X_train,u[:,0:k])\n",
    "    # X_regenerate = np.matmul(u[:,0:k] * s[0:k], vh[0:k,:])\n",
    "\n",
    "    # print(Z[0])\n",
    "\n",
    "    # print(X_train[0])\n",
    "    # print(X_regenerate[0])\n",
    "    # print((X_train - X_regenerate))\n",
    "    # print(np.sum(X_train - X_regenerate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.211303Z",
     "start_time": "2019-02-15T11:09:18.196993Z"
    }
   },
   "outputs": [],
   "source": [
    "def d():\n",
    "    U, s, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "    V = Vt.T\n",
    "\n",
    "    # PCs are already sorted by descending order \n",
    "    # of the singular values (i.e. by the\n",
    "    # proportion of total variance they explain)\n",
    "\n",
    "    # if we use all of the PCs we can reconstruct the noisy signal perfectly\n",
    "    S = np.diag(s)\n",
    "    Mhat = np.dot(U, np.dot(S, V.T))\n",
    "#     print \"Using all PCs, MSE = %.6G\" %(np.mean((M - Mhat)**2))\n",
    "\n",
    "#     # if we use only the first 20 PCs the reconstruction is less accurate\n",
    "#     Mhat2 = np.dot(U[:, :20], np.dot(S[:20, :20], V[:,:20].T))\n",
    "#     print \"Using first 20 PCs, MSE = %.6G\" %(np.mean((M - Mhat2)**2))\n",
    "\n",
    "    fig, [ax1, ax2, ax3] = plt.subplots(1, 3)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('true image')\n",
    "    ax2.imshow(noisy.mean(0))\n",
    "    ax2.set_title('mean of noisy images')\n",
    "    ax3.imshow((s[0]**(1./2) * V[:,0]).reshape(img.shape))\n",
    "    ax3.set_title('first spatial PC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:18.227761Z",
     "start_time": "2019-02-15T11:09:18.212836Z"
    }
   },
   "outputs": [],
   "source": [
    "def dum2():\n",
    "    from numpy import array\n",
    "    from numpy import diag\n",
    "    from numpy import zeros\n",
    "    from scipy.linalg import svd\n",
    "    # define a matrix\n",
    "    A = array([\n",
    "        [1,2,3,4,5,6,7,8,9,10],\n",
    "        [11,12,13,14,15,16,17,18,19,20],\n",
    "        [21,22,23,24,25,26,27,28,29,30]])\n",
    "    print(A.shape)\n",
    "    # Singular-value decomposition\n",
    "    U, s, VT = svd(A)\n",
    "\n",
    "    print(U.shape,s.shape,VT.shape)\n",
    "\n",
    "    # create m x n Sigma matrix\n",
    "    Sigma = zeros((A.shape[0], A.shape[1]))\n",
    "    # populate Sigma with n x n diagonal matrix\n",
    "    print(Sigma.shape)\n",
    "    print(diag(s).shape)\n",
    "    Sigma[:A.shape[0], :A.shape[0]] = diag(s)\n",
    "    # select\n",
    "    n_elements = 2\n",
    "    Sigma = Sigma[:, :n_elements]\n",
    "    VT = VT[:n_elements, :]\n",
    "    # reconstruct\n",
    "    B = U.dot(Sigma.dot(VT))\n",
    "    print(B)\n",
    "    # transform\n",
    "    T = U.dot(Sigma)\n",
    "    print(T)\n",
    "    T = A.dot(VT.T)\n",
    "    print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:19.310012Z",
     "start_time": "2019-02-15T11:09:18.229671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order:\n",
      "6.746801352285199\n",
      "4.858376586397841\n",
      "2.663128259708234\n",
      "1.8830937147253963\n",
      "1.4726026737586106\n",
      "1.3295144786680015\n",
      "1.1178166054530596\n",
      "1.0680006762499121\n",
      "1.0220487412307482\n",
      "1.0023062482157692\n",
      "0.9557215809334267\n",
      "0.9150570255508345\n",
      "0.7204221266551223\n",
      "0.65726555688893\n",
      "0.5000133713539052\n",
      "0.44789811490813014\n",
      "0.4070953169640057\n",
      "0.3613348322914822\n",
      "0.34116488552317364\n",
      "0.2095461033424774\n",
      "0.09735369784509215\n",
      "0.06680112977275586\n",
      "0.05217343049256102\n",
      "0.04230979607991051\n",
      "0.029656324577464612\n",
      "0.016579714911114023\n",
      "0.00979367064574685\n",
      "0.004605234395764877\n",
      "0.00151875017534643\n",
      "[ 23.26483225  40.01785496  49.20105586  55.69448246  60.77242271\n",
      "  65.3569554   69.21149542  72.89425637  76.41856237  79.87479082\n",
      "  83.17038247  86.32575153  88.80996576  91.07639871  92.80058275\n",
      "  94.34505901  95.74883597  96.99481815  98.17124879  98.89382156\n",
      "  99.22952396  99.45987269  99.63978107  99.78567691  99.8879401\n",
      "  99.94511153  99.97888281  99.99476293 100.        ]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "[[-1.90330308e+00  8.83008275e-01 -1.01770566e-01 ...  5.22426243e-03\n",
      "   3.71005131e-03 -2.58899082e-03]\n",
      " [ 3.30380557e+00  1.50492286e+00 -9.44968245e-02 ... -4.90067077e-03\n",
      "   1.05942529e-03  6.17929164e-03]\n",
      " [ 3.96173322e+00  1.16137728e+00  5.14015313e-02 ... -3.40787522e-04\n",
      "  -4.15577565e-03 -1.67546775e-03]\n",
      " ...\n",
      " [-2.42610328e+00  9.36416069e-01 -6.30394994e-02 ... -3.14746873e-03\n",
      "  -6.12065821e-04  2.59300901e-04]\n",
      " [-1.02898849e+00  4.33113390e-01  2.47964640e-02 ...  1.50696545e-02\n",
      "   3.09676441e-03 -6.39954142e-03]\n",
      " [ 4.22027459e+00  1.13959122e+00  3.35802937e-03 ... -1.36059195e-03\n",
      "  -4.29053437e-03 -2.44435252e-03]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = data_preprocessing()\n",
    "\n",
    "mean_vec = np.mean(X_train, axis=0)\n",
    "cov_mat = (X_train - mean_vec).T.dot((X_train - mean_vec)) / (X_train.shape[0])\n",
    "\n",
    "# print(cov_mat)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "print(cum_var_exp)\n",
    "\n",
    "x_data = [i+1 for i in range(29)]\n",
    "print(x_data)\n",
    "x_datax = [i for i in range(29)]\n",
    "print(x_datax)\n",
    "\n",
    "barplot = pd.DataFrame(\n",
    "    {'Principal Components': x_data,\n",
    "     'Variance': var_exp\n",
    "    })\n",
    "    \n",
    "barplot = barplot.melt('Principal Components',value_name='Variance')\n",
    "barplot_graph = sns.barplot(x=\"Principal Components\", y=\"Variance\", data=barplot)\n",
    "\n",
    "lineplot = pd.DataFrame(\n",
    "    {'Principal Components': x_datax,\n",
    "     'Variance': cum_var_exp\n",
    "    })\n",
    "    \n",
    "lineplot = lineplot.melt('Principal Components',value_name='Variance')\n",
    "lineplot_graph = sns.lineplot(x=\"Principal Components\", y=\"Variance\", data=lineplot)\n",
    "\n",
    "\n",
    "tl = []\n",
    "for i in range(len(cum_var_exp)):\n",
    "    if(cum_var_exp[i]<100):\n",
    "        tl.append(eig_pairs[i][1].tolist())\n",
    "    \n",
    "\n",
    "matrix_w= np.matrix(tl)\n",
    "print(np.dot(X_train,matrix_w.T))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pca = PCA(28)\n",
    "# # fit on data\n",
    "# # X_test_std = StandardScaler().fit_transform(X_train)\n",
    "# pca.fit(X_train)\n",
    "# # access values and vectors\n",
    "# #print(pca.components_)\n",
    "# # print(sorted(pca.explained_variance_, reverse=True))\n",
    "# # transform data\n",
    "# B = pca.transform(X_train)\n",
    "\n",
    "# tot = sum(pca.explained_variance_)\n",
    "# var_exp = [(i / tot)*100 for i in sorted(pca.explained_variance_, reverse=True)]\n",
    "# # print(var_exp)\n",
    "# cum_var_exp = np.cumsum(var_exp)\n",
    "# # print(cum_var_exp)\n",
    "# print(\"sdgsdgsdgsdgsgsd\")\n",
    "# # print(B.shape)\n",
    "# print(B)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:14:28.828837Z",
     "start_time": "2019-02-15T11:14:28.817450Z"
    }
   },
   "outputs": [],
   "source": [
    "def g():\n",
    "    from numpy import array\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(14)\n",
    "    # fit on data\n",
    "    # X_test_std = StandardScaler().fit_transform(X_train)\n",
    "    pca.fit(X_test_std)\n",
    "    # access values and vectors\n",
    "    #print(pca.components_)\n",
    "    print(sorted(pca.explained_variance_, reverse=True))\n",
    "    # transform data\n",
    "    B = pca.transform(X_test_std)\n",
    "\n",
    "    tot = sum(pca.explained_variance_)\n",
    "    var_exp = [(i / tot)*100 for i in sorted(pca.explained_variance_, reverse=True)]\n",
    "    # print(var_exp)\n",
    "    cum_var_exp = nump.cumsum(var_exp)\n",
    "    # print(cum_var_exp)\n",
    "\n",
    "    print(B.shape)\n",
    "    print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:09:53.554132Z",
     "start_time": "2019-02-15T11:09:53.519204Z"
    }
   },
   "outputs": [],
   "source": [
    "def dum():\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = data_preprocessing()\n",
    "\n",
    "    U, s, Vh = np.linalg.svd(X_train, full_matrices=False)\n",
    "    assert np.allclose(X_train, np.dot(U, np.dot(np.diag(s), Vh)))\n",
    "    S = s\n",
    "    s[21:] = 0\n",
    "    new_a = np.dot(U, np.dot(np.diag(s), Vh))\n",
    "\n",
    "    # print(X_train[0])\n",
    "    # print(new_a[0])\n",
    "\n",
    "    Sigma = zeros((X_train.shape[0], X_train.shape[1]))\n",
    "    Sigma[:X_train.shape[1], :X_train.shape[1]] = diag(S)\n",
    "\n",
    "    print(Vh.shape)\n",
    "\n",
    "    Vh = Vh[:, :20]\n",
    "    X_transformed = np.dot(X_train,Vh)\n",
    "    print(X_transformed.shape)\n",
    "    print(X_transformed[0])\n",
    "\n",
    "    # X_transformed = np.dot(U,Sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from numpy import array\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(20)\n",
    "    # fit on data\n",
    "    # X_test_std = StandardScaler().fit_transform(X_train)\n",
    "    pca.fit(X_train)\n",
    "    # access values and vectors\n",
    "    #print(pca.components_)\n",
    "    # print(sorted(pca.explained_variance_, reverse=True))\n",
    "    # transform data\n",
    "    B = pca.transform(X_train)\n",
    "\n",
    "    # tot = sum(pca.explained_variance_)\n",
    "    # var_exp = [(i / tot)*100 for i in sorted(pca.explained_variance_, reverse=True)]\n",
    "    # # print(var_exp)\n",
    "    # cum_var_exp = np.cumsum(var_exp)\n",
    "    # # print(cum_var_exp)\n",
    "\n",
    "    print(B.shape)\n",
    "    print(B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T11:30:22.574203Z",
     "start_time": "2019-02-15T11:30:02.546385Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11342238 -0.41786933 -0.05197784 -0.00165902 -0.08914433 -0.02542923\n",
      " -0.02265932 -0.02246624 -0.0226605  -0.04289901 -0.57769839  0.11071201\n",
      " -0.63488625 -0.62913584 -0.3740491  -0.37436668  0.76550954 -0.34690465\n",
      " -0.06426229  0.73697818  1.25229592  1.05942512 -0.43977497 -0.48094924\n",
      " -0.28927264 -0.63672005 -0.62347713 -0.38814025 -0.37471995]\n",
      "[-1.14870711e-01 -4.19236226e-01 -5.08876664e-02 -4.22856248e-04\n",
      " -8.84859351e-02 -2.40800040e-02 -2.16345646e-02 -2.36503193e-02\n",
      " -2.28144724e-02 -4.23208049e-02 -5.79353521e-01  1.12609564e-01\n",
      " -6.34950206e-01 -6.30687354e-01 -3.80032989e-01 -3.71581943e-01\n",
      "  7.67611546e-01 -3.43220436e-01 -6.20558418e-02  7.21909624e-01\n",
      "  1.32464203e+00  9.71536828e-01 -4.49847792e-01 -4.69471029e-01\n",
      " -2.84650670e-01 -6.30334467e-01 -6.29455783e-01 -3.75180259e-01\n",
      " -3.83860348e-01]\n",
      "[-1.90330308e+00 -8.83008275e-01  1.01770566e-01 -1.17502703e+00\n",
      "  5.99327404e-01  3.16392949e-01  1.23790061e-01  1.14563527e-01\n",
      "  2.97856004e-01 -3.06782989e-02 -1.40612872e-03  3.28725929e-02\n",
      "  4.64922769e-02  3.68798831e-01  3.10507344e-01  5.40227071e-01\n",
      "  3.70975432e-02 -1.74224530e-01 -4.69124770e-01 -3.22023215e-02]\n",
      "(17498, 20)\n",
      "[-1.90330308e+00 -8.83008275e-01  1.01770566e-01 -1.17502703e+00\n",
      "  5.99327404e-01  3.16392949e-01  1.23790061e-01  1.14563527e-01\n",
      "  2.97856004e-01 -3.06782989e-02 -1.40612872e-03  3.28725929e-02\n",
      "  4.64922769e-02  3.68798831e-01  3.10507344e-01  5.40227071e-01\n",
      "  3.70975432e-02 -1.74224530e-01 -4.69124770e-01 -3.22023215e-02]\n",
      "(17498, 20)\n",
      "(17498, 20)\n",
      "[-1.90330308e+00 -8.83008275e-01 -1.01770566e-01 -1.17502703e+00\n",
      " -5.99327404e-01  3.16392949e-01 -1.23790061e-01  1.14563527e-01\n",
      " -2.97856004e-01 -3.06782989e-02 -1.40612872e-03 -3.28725929e-02\n",
      "  4.64922769e-02  3.68798831e-01 -3.10507344e-01  5.40227071e-01\n",
      " -3.70975432e-02 -1.74224530e-01  4.69124770e-01  3.22023215e-02]\n"
     ]
    }
   ],
   "source": [
    "A, X_validation, y_train, y_validation = data_preprocessing()\n",
    "# A = A.T\n",
    "U, s, VT = svd(A)\n",
    "# create m x n Sigma matrix\n",
    "Sigma = np.zeros((A.shape[0], A.shape[1]))\n",
    "# populate Sigma with n x n diagonal matrix\n",
    "Sigma[:A.shape[1], :A.shape[1]] = np.diag(s)\n",
    "# select\n",
    "n_elements = 20\n",
    "Sigma = Sigma[:, :n_elements]\n",
    "VT = VT[:n_elements, :]\n",
    "# reconstruct\n",
    "B = np.dot(U,np.dot(Sigma,VT))\n",
    "print(A[0])\n",
    "print(B[0])\n",
    "# transform\n",
    "T = np.dot(U,Sigma)\n",
    "print(T[0])\n",
    "print(T.shape)\n",
    "T = np.dot(A,VT.T)\n",
    "print(T[0])\n",
    "print(T.shape)\n",
    "\n",
    "# A = A.T\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(20)\n",
    "# fit on data\n",
    "# X_test_std = StandardScaler().fit_transform(X_train)\n",
    "pca.fit(A)\n",
    "# access values and vectors\n",
    "#print(pca.components_)\n",
    "# print(sorted(pca.explained_variance_, reverse=True))\n",
    "# transform data\n",
    "B = pca.transform(A)\n",
    "print(B.shape)\n",
    "print(B[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
